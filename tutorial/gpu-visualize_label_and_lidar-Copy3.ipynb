{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "from pyson.utils import print_source, multi_thread, read_json\n",
    "import mmcv\n",
    "\n",
    "import numpy as np\n",
    "import math\n",
    "import cv2\n",
    "import io\n",
    "# from waymo_open_dataset import dataset_pb2 as open_dataset\n",
    "import sys\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "import os\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from simple_waymo_open_dataset_reader import WaymoDataFileReader\n",
    "from simple_waymo_open_dataset_reader import dataset_pb2, label_pb2\n",
    "from simple_waymo_open_dataset_reader import utils\n",
    "from utils import *\n",
    "import matplotlib.cm\n",
    "from glob import glob\n",
    "from pyson.utils import read_json\n",
    "# os.environ['CUDA_VISIBLE_DEVICES']='0'\n",
    "\n",
    "cmap = matplotlib.cm.get_cmap(\"viridis\")\n",
    "tf.enable_eager_execution()\n",
    "\n",
    "# tf.config.gpu.set_per_process_memory_fraction(0.75)\n",
    "# tf.config.experimental.set_per_process_memory_growth(True)\n",
    "\n",
    "data_paths_train =  glob('/ssd6/waymo/tfrecord_train/*.tfrecord')#[_ for _ in]# if not _ in data_paths_val]\n",
    "output_dir = '/ssd6/coco_style_1.2/'\n",
    "out_laser_dir = output_dir + '/laser_images'\n",
    "out_image_dir = output_dir + '/images'\n",
    "out_json_dir = output_dir + '/annotations/output_json'\n",
    "os.makedirs(out_laser_dir, exist_ok=1)\n",
    "os.makedirs(out_image_dir, exist_ok=1)\n",
    "os.makedirs(out_json_dir, exist_ok=1)\n",
    "\n",
    "\n",
    "def f_datapath(data_path):\n",
    "    f_name = os.path.basename(data_path)\n",
    "    frame_name = os.path.basename(data_path)\n",
    "    frame_id = 0\n",
    "    dataset = tf.data.TFRecordDataset(data_path, compression_type='')\n",
    "    frames = []\n",
    "    for data in dataset:\n",
    "        frame_id += 1\n",
    "        frame = dataset_pb2.Frame()\n",
    "        frame.ParseFromString(bytearray(data.numpy()))\n",
    "        frames.append((frame, frame_id, f_name))\n",
    "    return frames\n",
    "\n",
    "anno = read_json('/ssd6/coco_style_1.2/annotations/test.json')\n",
    "\n",
    "from pyson.utils import timeit\n",
    "\n",
    "\n",
    "def f_frame_data(frame_data):\n",
    "    frame, frame_id, frame_name = frame_data\n",
    "    laser_name = dataset_pb2.LaserName.TOP\n",
    "    laser = utils.get(frame.lasers, laser_name)\n",
    "    laser_calibration = utils.get(frame.context.laser_calibrations, laser_name)\n",
    "    ri, camera_projection, range_image_pose = utils.parse_range_image_and_camera_projection(laser)\n",
    "    pcl, pcl_attr = utils.project_to_pointcloud(frame, ri, camera_projection, range_image_pose, laser_calibration)\n",
    "    result = {}\n",
    "    for camera_name in camera_names:\n",
    "        camera_calibration = utils.get(frame.context.camera_calibrations, camera_name)\n",
    "        camera = utils.get(frame.images, camera_name)\n",
    "        image_name = dataset_pb2.CameraName.Name.Name(camera_name)\n",
    "        output_name = os.path.join(output_dir, 'images', f'{frame_name}_{frame_id}_{image_name}.jpg')\n",
    "        if os.path.exists(output_name):\n",
    "            img = cv2.imread(output_name)\n",
    "            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        else:\n",
    "            # Decode the image\n",
    "            img = utils.decode_image(camera)\n",
    "            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "            cv2.imwrite(output_name, img)\n",
    "            # BGR to RGB\n",
    "\n",
    "        \n",
    "         # Get the transformation matrix for the camera.\n",
    "        vehicle_to_image = utils.get_image_transform(camera_calibration)\n",
    "        vehicle_to_labels = []\n",
    "        for label in frame.laser_labels:\n",
    "            vehicle_to_label = np.linalg.inv(utils.get_box_transformation_matrix(label.box))\n",
    "            vehicle_to_labels.append(vehicle_to_label)\n",
    "\n",
    "\n",
    "        vehicle_to_labels = np.stack(vehicle_to_labels)\n",
    "        # Convert the pointcloud to homogeneous coordinates.\n",
    "        pcl1 = np.concatenate((pcl,np.ones_like(pcl[:,0:1])),axis=1)\n",
    "        # Transform the point cloud to the label space for each label.\n",
    "        # proj_pcl shape is [label, LIDAR point, coordinates]\n",
    "        # np ----\n",
    "        # proj_pcl = np.einsum('lij,bj->lbi', vehicle_to_labels, pcl1)\n",
    "        # tf\n",
    "#         tf_vehicle_to_labels = tf.convert_to_tensor(vehicle_to_labels)\n",
    "#         tf_pcl1 = tf.convert_to_tensor(pcl1)\n",
    "#         proj_pcl = tf.einsum('lij,bj->lbi', tf_vehicle_to_labels, tf_pcl1).numpy()\n",
    "        # torch\n",
    "        device = \"cpu\"#torch.device(f'cuda:{frame_id%4}')\n",
    "        torch_vehicle_to_labels = torch.from_numpy(vehicle_to_labels.astype(np.float32)).to(device)\n",
    "        torch_pcl1 = torch.from_numpy(pcl1.astype(np.float32)).to(device)\n",
    "        proj_pcl = torch.einsum('lij,bj->lbi', torch_vehicle_to_labels, torch_pcl1).cpu().numpy()\n",
    "        \n",
    "        mask = np.logical_and.reduce(np.logical_and(proj_pcl >= -1, proj_pcl <= 1),axis=2)\n",
    "\n",
    "        # Count the points inside each label's box.\n",
    "        counts = mask.sum(1)\n",
    "        # Keep boxes which contain at least 10 LIDAR points.\n",
    "        visibility = counts > 10\n",
    "\n",
    "        # Display the LIDAR points on the image.\n",
    "        laser_as_img = np.zeros_like(img)\n",
    "        display_laser_on_image(laser_as_img, pcl, vehicle_to_image, pcl_attr)\n",
    "        output_laser_name = os.path.join(out_laser_dir, os.path.basename(output_name))\n",
    "        box_3d_list = get_3d_points(camera_calibration, frame.laser_labels)\n",
    "        box_2d_list = get_2d_bbox(frame, camera_name)\n",
    "        if not os.path.exists(output_laser_name):\n",
    "            cv2.imwrite(output_laser_name, laser_as_img)\n",
    "        result[output_name] = dict(box_3d_list=box_3d_list, box_2d_list=box_2d_list,\n",
    "                                   visibility=visibility.tolist())\n",
    "        return result\n",
    "\n",
    "camera_names = [dataset_pb2.CameraName.FRONT, dataset_pb2.CameraName.FRONT_LEFT, dataset_pb2.CameraName.FRONT_RIGHT, dataset_pb2.CameraName.SIDE_LEFT, dataset_pb2.CameraName.SIDE_RIGHT]\n",
    "paths = [p for p in data_paths_train if not os.path.exists(out_json_dir+\"/\"+os.path.basename(p)+'.json')]\n",
    "\n",
    "\n",
    "for i, filename in enumerate(paths):\n",
    "    out_json = out_json_dir+\"/\"+os.path.basename(filename)+'.json'\n",
    "    out = dict()\n",
    "    print(i, filename, '/', len(paths))\n",
    "    frames_data = f_datapath(filename)\n",
    "    outs = multi_thread(f_frame_data, frames_data, verbose=1, max_workers=8)\n",
    "    for _ in out:\n",
    "        out.update(out)\n",
    "        \n",
    "    print('-----------------------')\n",
    "    with open(out_json, 'w') as f:\n",
    "        json.dump(out, f)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
